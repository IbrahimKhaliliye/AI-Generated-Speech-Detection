{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bb68ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e38799",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to convert MP3 to WAV\n",
    "def convert_mp3_to_wav(mp3_file, wav_file):\n",
    "    audio = AudioSegment.from_mp3(mp3_file)\n",
    "    audio.export(wav_file, format=\"wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac61a535",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to extract features from WAV files\n",
    "def extract_features(file_name):\n",
    "    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_scaled = np.mean(mfccs.T, axis=0)\n",
    "    return mfccs_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68c5f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to load dataset\n",
    "def load_data(mp3_files, labels):\n",
    "    features = []\n",
    "    for file in mp3_files:\n",
    "        wav_file = file.replace('.mp3', '.wav')\n",
    "        convert_mp3_to_wav(file, wav_file)\n",
    "        features.append(extract_features(wav_file))\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Example usage\n",
    "mp3_files = ['file1.mp3', 'file2.mp3']  # Replace with your mp3 files\n",
    "labels = ['AI', 'Human']  # Corresponding labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c950cddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocess data\n",
    "X, y = load_data(mp3_files, labels)\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=2)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddba43ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build model\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(40,), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146878cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36001685",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
